{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "tf.config.experimental.set_memory_growth(physical_devices[3], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3778,
     "status": "ok",
     "timestamp": 1600173817773,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "djyY9g8LBNPF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,Flatten,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1600173964387,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "WA-HO8kFfrKG"
   },
   "outputs": [],
   "source": [
    "output_dir = os.getcwd()\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1600173988959,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "RUy0Bh00MEzm"
   },
   "outputs": [],
   "source": [
    "memory_size = 15_000\n",
    "gamma = 0.9995\n",
    "learning_rate= 0.001\n",
    "mini_batch_size = 32\n",
    "\n",
    "\n",
    "state_size = (210,160,1)\n",
    "n_episodes = 10_000\n",
    "\n",
    "epsilon_max = 1\n",
    "epsilon_min = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2238,
     "status": "ok",
     "timestamp": 1600173991669,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "a_FhAxiyCtQ5",
    "outputId": "696a98d1-5164-44b8-b1c1-0d29b4b8c9a0"
   },
   "outputs": [],
   "source": [
    "name= \"Breakout-v0\"\n",
    "env = gym.make(name)\n",
    "action_size = env.action_space.n\n",
    "action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1600173995473,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "nT01jq0cyQiN"
   },
   "outputs": [],
   "source": [
    "def process(state1,state2,state3,state4):\n",
    "    \n",
    "    def pre(state):\n",
    "        s1 = state.astype('float')\n",
    "        s1 = s1/255\n",
    "        s1 = tf.image.resize(s1, (84, 84))\n",
    "        s1 = tf.image.rgb_to_grayscale(s1)\n",
    "        \n",
    "        return s1\n",
    "    \n",
    "    st1 = pre(state1)\n",
    "    st2 = pre(state2)\n",
    "    st3 = pre(state3)\n",
    "    st4 = pre(state4)\n",
    "    \n",
    "    states =  np.array(tf.concat((st1,st2,st3,st4),axis=2))\n",
    "    \n",
    "    states =  np.expand_dims(states,axis=0)\n",
    "    \n",
    "    return states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1600173997154,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "dxFcJb0kBjoL"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "  def __init__(self,memory_size,action_size):\n",
    "    self.action_size=action_size\n",
    "    self.gamma = 0.99\n",
    "    self.epsilon = 1\n",
    "    self.epsilon_decay = 0.999999\n",
    "    self.epsilon_min = 0.1\n",
    "    self.action_model  = self.build_model()\n",
    "    self.target_model =  self.build_model()\n",
    "    self.target_model.set_weights(self.action_model.get_weights())\n",
    "    self.swap_model = self.build_model()\n",
    "    self.memory = deque()   \n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "  def remember(self,state,action,reward,next_state,done):\n",
    "    if len(self.memory)>memory_size:\n",
    "      random.shuffle(self.memory)\n",
    "      self.memory.popleft()\n",
    "    self.memory.append((state,action,reward,next_state,done))\n",
    "\n",
    "  def build_model(self):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(8,8),strides=4, activation='relu', input_shape=(84,84,4)))\n",
    "    model.add(Conv2D(64, kernel_size=(4,4),strides=2, activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides = 1, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(action_size,activation='linear'))\n",
    "    model.compile(loss = tf.keras.losses.Huber(),optimizer = tf.keras.optimizers.Adam(lr = 0.00025))\n",
    "    return model\n",
    "\n",
    "  def act(self,state, epsilon = epsilon_min):\n",
    "    if np.random.random()<=epsilon:\n",
    "        return random.randrange(self.action_size)\n",
    "    else:\n",
    "        act_value  = self.action_model.predict(state)\n",
    "        return np.argmax(act_value[0])\n",
    "\n",
    "\n",
    "  def replay(self,minibatch_size):\n",
    "    random.shuffle(self.memory)\n",
    "    minibatch = random.sample(self.memory,mini_batch_size)\n",
    "    St0 = np.zeros((1, 84, 84, 4))\n",
    "    St1 = np.zeros((1, 84, 84, 4))\n",
    "    for state, _, _, next_state, _ in minibatch:\n",
    "        St0 = np.concatenate((St0, state), axis = 0)\n",
    "        St1 = np.concatenate((St1, next_state), axis = 0)#for vectorizing the operations\n",
    "      \n",
    "    St0 = St0[1:]\n",
    "    St1 = St1[1:]\n",
    "    target_not_done = self.target_model.predict(St1)\n",
    "    target_f = self.action_model.predict(St0)\n",
    "    \n",
    "    i = 0\n",
    "    for _, action, reward, _, done in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward  + self.gamma* np.amax(target_not_done[i])\n",
    "        \n",
    "        target_f[i][action] =  target\n",
    "        i += 1\n",
    "\n",
    "    self.action_model.fit(St0 , target_f, verbose= 0)\n",
    "        \n",
    "    if self.epsilon>self.epsilon_min:\n",
    "       self.epsilon *= self.epsilon_decay\n",
    "\n",
    "  def replace_weights(self):\n",
    "    self.swap_model.set_weights(self.action_model.get_weights())\n",
    "    self.action_model.set_weights(self.target_model.get_weights())\n",
    "\n",
    "    self.target_model.set_weights(self.swap_model.get_weights())\n",
    "  \n",
    "  def load(self,name):\n",
    "    self.action_model.load_weights(name)\n",
    "    self.target_model.load_weights(name)\n",
    "        \n",
    "   \n",
    "  def save(self,name):\n",
    "    self.action_model.save_weights(name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1211,
     "status": "ok",
     "timestamp": 1600174224953,
     "user": {
      "displayName": "Himanshu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdCauOgU9YQTaR_WFJvGdZRC_ld0a9KtQG1s11uA=s64",
      "userId": "15127769422975897532"
     },
     "user_tz": -330
    },
    "id": "-6B7weW0FB7y"
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent(memory_size,action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4Ap-UwkcFpv9",
    "outputId": "9e8f0e4b-b4dc-4a14-d07b-9ebb651735de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    done = False\n",
    "    states = deque()\n",
    "    time_step_count = 0\n",
    "    env.reset()\n",
    "    for i in range(4):\n",
    "        init_state = env.step(random.randrange(action_size))\n",
    "        states.append(init_state[0])\n",
    "    updated_states = states.copy()\n",
    "    current_states = process(states[0],states[1],states[2],states[3])\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        env.reset()\n",
    "        \n",
    "        cum_reward=0\n",
    "        for time_step in range(20_000):\n",
    "            if time_step_count <= 1000_000* epsilon_max:\n",
    "                epsilon = epsilon_max - (epsilon_max - epsilon_min) * time_step_count / (epsilon_max *1_000_000)\n",
    "            else:\n",
    "                epsilon = epsilon_min\n",
    "            action = agent.act(current_states)\n",
    "            next_state,reward,done,_=env.step(action)\n",
    "            updated_states.popleft()\n",
    "            \n",
    "            updated_states.append(next_state)\n",
    "            new_states = process(updated_states[0],updated_states[1],updated_states[2],updated_states[3])\n",
    "        \n",
    "            reward = reward if not done else -10\n",
    "            cum_reward +=reward\n",
    "            agent.remember(current_states,action,reward,new_states,done)\n",
    "            #current_states\n",
    "            current_states =  new_states.copy()\n",
    "            #del new_states\n",
    "            if time_step_count <2000:\n",
    "                print(f\"Time Step:{time_step_count}, Action: {action}, Reward: {reward}, Exploration: {epsilon}\")\n",
    "\n",
    "            \n",
    "        \n",
    "            if len(agent.memory)>4*mini_batch_size and time_step_count%4 == 0:\n",
    "                agent.replay(mini_batch_size)\n",
    "    \n",
    "            if time_step_count%10_000 == 0:\n",
    "                agent.replace_weights()\n",
    "                agent.save(output_dir + '/' + 'Breakout_new'+ '.hdf5')\n",
    "            \n",
    "            time_step_count += 1\n",
    "            \n",
    "            if done:\n",
    "                print(len(agent.memory))\n",
    "                print(\"example: {}, average reward: {}, episode: {}, exploration :{}\".format(time_step_count, cum_reward, episode, epsilon))\n",
    "                break\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    done = False\n",
    "    states = deque()\n",
    "    env.reset()\n",
    "    time_step_count = 0\n",
    "    for i in range(4):\n",
    "        init_state = env.step(random.randrange(action_size))\n",
    "        states.append(init_state[0])\n",
    "    updated_states = states.copy()\n",
    "    current_states = process(states[0],states[1],states[2],states[3])\n",
    "\n",
    "    for episode in range(100):\n",
    "    \n",
    "        env.reset()\n",
    "        cum_reward=0\n",
    "        for time_step in range(20_000):\n",
    "            action = agent.act(current_states)\n",
    "            next_state,reward,done,_=env.step(action)\n",
    "            env.render()\n",
    "            updated_states.popleft()\n",
    "            updated_states.append(next_state)\n",
    "            new_states = process(updated_states[0],updated_states[1],updated_states[2],updated_states[3])\n",
    "            \n",
    "            reward = reward if not done else -10\n",
    "            cum_reward +=reward\n",
    "            del current_states\n",
    "            current_states =  new_states.copy()\n",
    "            del new_states\n",
    "            \n",
    "            if time_step_count <2000:\n",
    "                print(f\"Time Step:{time_step_count}, Action: {action}, Reward: {reward}\")\n",
    "            \n",
    "            time_step_count += 1\n",
    "            \n",
    "            if done:\n",
    "                \n",
    "                print(\"time step: {}, average reward: {}, episode: {}\".format(time_step_count, cum_reward ,episode))\n",
    "                break\n",
    "         \n",
    "    env.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8a1zsXCyQiu",
    "outputId": "67f09b20-af04-4e54-f069-a41049afddaa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Breakout .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
